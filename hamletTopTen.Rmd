---
title: "Hamlet Top Ten Words"
author: "CyberDH"
date: "2015"
output: html_document
---

***  
### Global parameters 
#### Set working directory
```{r}
setwd("~/cyberdh/HILT-demo")
```

#### Include necessary packages for notebook
```{r}
library(knitr)
library(markdown)
library(rmarkdown)
```

#### Load data (plaintext file), formatted by line breaks  
```{r}
text.v <- scan("hamlet.txt", what="character", sep="\n")
```

***   
### Prepare text data
#### Collapse text into one string, leaving spaces " " between words 
```{r}
hamlet.v <- paste(text.v, collapse="  ")
```

#### Convert text string to all lower-case letters
```{r}
hamlet.lower.v <- tolower(hamlet.v)
```

#### Split (_strsplit_) big string into separate words
```{r}
hamlet.words <- strsplit(hamlet.lower.v, "\\W")
```

#### Simplify items by reducing the list to a vector 
```{r}
hamlet.word.v <- unlist(hamlet.words)
```

#### Eliminate blanks left by punctuation; overwrite "hamlet.word.v"
```{r}
not.blanks.v <- which(hamlet.word.v != "")
hamlet.word.v <- hamlet.word.v[not.blanks.v]
```

***   
### Analysis
#### Number of unique words in the text
```{r}
length(unique(hamlet.word.v))
```

***    
#### Create a sorted table of “contingency” word types and their corresponding frequencies.
```{r}
hamlet.freqs.t <- table(hamlet.word.v)
sorted.hamlet.freqs.t <- sort(hamlet.freqs.t, decreasing=TRUE)
```

***   
#### Calculate whether text conforms to Zipf’s Law: _the frequency of any word in a corpus is inversely proportional to its “rank” or position in the overall frequency distribution_.
```{r}
sorted.hamlet.rel.freqs.t <- 100*(sorted.hamlet.freqs.t/sum(sorted.hamlet.freqs.t))
```

***    
#### Plot the result
```{r}
plot(sorted.hamlet.rel.freqs.t[1:10], type="b", main="Hamlet, Entire Play", xlab="Top Ten Words", 
     ylab="Percentage of Speech", xaxt="n",)
axis(1,1:10, labels=names(sorted.hamlet.rel.freqs.t[1:10]))
```


Acknowledgments: Code adapted from Matthew Jockers' _Text Analysis with R for Students of Literature_.
